{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The bot receives tweets via mentions and in turn performs sentiment analysis on the most recent twitter account specified in the mention\n",
    "\n",
    "For example, when a user tweets, \"@PlotBot Analyze: @CNN,\" it will trigger a sentiment analysis on the CNN twitter feed.\n",
    "\n",
    "A plot from the sentiment analysis is then tweeted to the PlotBot5 twitter feed.\n",
    "\n",
    "Hints, requirements, and considerations:\n",
    "\n",
    "Your bot should scan your account every five minutes for mentions.\n",
    "Your bot should pull 500 most recent tweets to analyze for each incoming request.\n",
    "Your script should prevent abuse by analyzing only Twitter accounts that have not previously been analyzed.\n",
    "Your plot should include meaningful legend and labels.\n",
    "It should also mention the Twitter account name of the requesting user.\n",
    "When submitting your assignment, be sure to have at least three analyses tweeted out from your account (enlist the help of classmates, friends, or family, if necessary!).\n",
    "Notable libraries used to complete this application include: Matplotlib, Pandas, Tweepy, TextBlob, and Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tweepy\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Authentication\n",
    "from secrets import chirp\n",
    "\n",
    "# Deal with sentiments\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_tweets(account):\n",
    "    '''\n",
    "    INPUT: String: Twitter Account Name\n",
    "    OUTPUT: Panda's DataFrame: \"Ago\" tweets ago \"Compound\" vader compound score\n",
    "    '''\n",
    "    sentiments = []\n",
    "    counter = -1\n",
    "    for x in range(25):\n",
    "        public_tweets = chirp.user_timeline(account, page=x)\n",
    "        for tweet in public_tweets:\n",
    "            result = analyzer.polarity_scores(tweet[\"text\"])\n",
    "            sentiments.append({\n",
    "                \"Ago\": counter,\n",
    "                \"Compound\": result[\"compound\"],\n",
    "                \"User\": account\n",
    "            })\n",
    "            counter -= 1\n",
    "    df = pd.DataFrame(sentiments)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_work(analyzed=[], last_check=None, own_account=\"GunmaKuma\"):\n",
    "    now = datetime.datetime.now()\n",
    "    str_now = str(now)\n",
    "    str_now = str_now[:10]\n",
    "    sweep = chirp.home_timeline(since_id=last_check)\n",
    "    users = []\n",
    "    for tweet in sweep:\n",
    "        request_user = tweet[\"user\"][\"screen_name\"]\n",
    "        last_check = int(tweet[\"id_str\"])\n",
    "        try:\n",
    "            first_at = tweet[\"entities\"][\"user_mentions\"][0][\"screen_name\"]\n",
    "            second_at = tweet[\"entities\"][\"user_mentions\"][1][\"screen_name\"]\n",
    "            if((first_at == own_account) and (second_at not in analyzed)):\n",
    "                df = pull_tweets(second_at)\n",
    "                plt.figure(figsize=(10,7))\n",
    "                sns.set()\n",
    "                plt.plot(df[\"Ago\"], df[\"Compound\"], \"bo-\", label=f\"@{df['User'][0]}\", alpha=0.7)\n",
    "                plt.legend(loc=(1,.95))\n",
    "                plt.xlabel(\"Tweets Ago\")\n",
    "                plt.ylabel(\"Tweet Polarity\")\n",
    "                plt.xlim(-len(df[\"Ago\"]) - 5, 5)\n",
    "                plt.ylim(-1.01, 1.01)\n",
    "                plt.title(f\"Sentiment Analysis of Tweets ({str_now})\")\n",
    "                plt.savefig(f\"{second_at}.png\")\n",
    "                plt.close()\n",
    "                chirp.update_with_media(f\"{second_at}.png\", f\"Tweet Analysis of @{second_at} (You're welcome, @{request_user})\")\n",
    "                analyzed.append(second_at)\n",
    "                print(\"Tweeted, sir!\")\n",
    "        except tweepy.TweepError:\n",
    "            print(\"Something's up with twitter...\" + e.reason)\n",
    "        except:\n",
    "            print(\"Nothing to do\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweeted, sir!\n",
      "Tweeted, sir!\n",
      "Nothing to do\n",
      "Tweeted, sir!\n",
      "Tweeted, sir!\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n"
     ]
    }
   ],
   "source": [
    "analyzed = []\n",
    "while True:\n",
    "    try:\n",
    "        the_work(analyzed)\n",
    "    except tweepy.RateLimitError:\n",
    "        time.sleep(60 * 15)\n",
    "        continue\n",
    "    time.sleep(60 * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
